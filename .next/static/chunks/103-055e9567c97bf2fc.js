"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[103],{1692:(e,t,i)=>{i.d(t,{A:()=>a});let a=()=>{let e=document.querySelector(".tj-project-4-wrappper"),t=()=>{let e=window.innerWidth;return e>=992&&e<=1199?60:e>=768&&e<=991?50:125},a=null==e?void 0:e.querySelectorAll("img");new Promise(e=>{let t=0;null==a||a.forEach(i=>{i.complete?t++:(i.addEventListener("load",()=>{++t===(null==a?void 0:a.length)&&e()}),i.addEventListener("error",()=>{++t===(null==a?void 0:a.length)&&e()}))}),t===(null==a?void 0:a.length)&&e()}).then(()=>{i.e(151).then(i.t.bind(i,151,23)).then(e=>{let{default:i}=e,a=document.querySelector(".tj-project-4-wrappper");if(a){let e=new i(a,{itemSelector:".tj-project-4-item",percentPosition:!0,masonry:{columnWidth:".tj-project-4-item",gutter:t()}});window.addEventListener("resize",()=>{e.options.masonry.gutter=t(),e.layout()})}})})}},3096:(e,t,i)=>{i.d(t,{Wx:()=>d});var a=i(2115),n=Object.defineProperty,s=(e,t,i)=>t in e?n(e,t,{enumerable:!0,configurable:!0,writable:!0,value:i}):e[t]=i,r=new Map,o=new WeakMap,l=0,c=void 0;function d(){var e;let{threshold:t,delay:i,trackVisibility:n,rootMargin:s,root:d,triggerOnce:g,skip:h,initialInView:u,fallbackInView:p,onChange:m}=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},[y,f]=a.useState(null),b=a.useRef(m),[v,P]=a.useState({inView:!!u,entry:void 0});b.current=m,a.useEffect(()=>{let e;if(!h&&y)return e=function(e,t){let i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{},a=arguments.length>3&&void 0!==arguments[3]?arguments[3]:c;if(void 0===window.IntersectionObserver&&void 0!==a){let n=e.getBoundingClientRect();return t(a,{isIntersecting:a,target:e,intersectionRatio:"number"==typeof i.threshold?i.threshold:0,time:0,boundingClientRect:n,intersectionRect:n,rootBounds:n}),()=>{}}let{id:n,observer:s,elements:d}=function(e){let t=Object.keys(e).sort().filter(t=>void 0!==e[t]).map(t=>{var i;return"".concat(t,"_").concat("root"===t?(i=e.root)?(o.has(i)||(l+=1,o.set(i,l.toString())),o.get(i)):"0":e[t])}).toString(),i=r.get(t);if(!i){let a,n=new Map,s=new IntersectionObserver(t=>{t.forEach(t=>{var i;let s=t.isIntersecting&&a.some(e=>t.intersectionRatio>=e);e.trackVisibility&&void 0===t.isVisible&&(t.isVisible=s),null==(i=n.get(t.target))||i.forEach(e=>{e(s,t)})})},e);a=s.thresholds||(Array.isArray(e.threshold)?e.threshold:[e.threshold||0]),i={id:t,observer:s,elements:n},r.set(t,i)}return i}(i),g=d.get(e)||[];return d.has(e)||d.set(e,g),g.push(t),s.observe(e),function(){g.splice(g.indexOf(t),1),0===g.length&&(d.delete(e),s.unobserve(e)),0===d.size&&(s.disconnect(),r.delete(n))}}(y,(t,i)=>{P({inView:t,entry:i}),b.current&&b.current(t,i),i.isIntersecting&&g&&e&&(e(),e=void 0)},{root:d,rootMargin:s,threshold:t,trackVisibility:n,delay:i},p),()=>{e&&e()}},[Array.isArray(t)?t.toString():t,y,d,s,g,h,n,p,i]);let k=null==(e=v.entry)?void 0:e.target,w=a.useRef(void 0);y||!k||g||h||w.current===k||(w.current=k,P({inView:!!u,entry:void 0}));let A=[f,v.inView,v.entry];return A.ref=A[0],A.inView=A[1],A.entry=A[2],A}a.Component},4183:(e,t,i)=>{i.d(t,{A:()=>n});let a=JSON.parse('[{"id":1,"title":"ResumeGenius","category":"Full-Stack App","img":"/img/portfolio/resumegenius-thumb.jpg","shortDesc":"An AI-powered resume scoring and improvement tool built using React, Node.js, and Python NLP.","desc":"ResumeGenius is a full-stack AI application that evaluates resumes using semantic analysis and keyword matching techniques. It generates detailed feedback and ATS-optimized suggestions for candidates.","desc1":"I developed the full system including a React frontend, Express backend, and a Python microservice integrated with HuggingFace-hosted models for semantic scoring.","desc2":"This project helped me enhance my full-stack skills while implementing real-world AI solutions like LLMs, resume parsing, and intelligent feedback generation.","statusItem":[{"title":"Category","desc":"Full-Stack App"},{"title":"Type","desc":"Personal Project"},{"title":"Start Date","desc":"March 2024"},{"title":"Technologies","desc":"React, Node.js, HuggingFace, Python"}],"descItems":[{"title":"Project Goal","desc":"To create a free resume evaluation platform leveraging LLMs and ATS-style scoring logic."},{"title":"My Role","desc":"Designed and built the full-stack architecture, integrated LLM APIs, and handled semantic scoring."},{"title":"Key Features","desc":"Resume parsing, semantic matching, keyword gap analysis, skill suggestions, ATS score generation."}],"liveLink":"https://resumegenius-ui.vercel.app","githubLink":"https://github.com/adithya-crypto/Complete-resume-genius"},{"id":2,"title":"Jarvis Virtual Assistant","category":"AI/LLM Project","img":"/img/portfolio/jarvis-thumb.jpg","shortDesc":"AI-driven virtual assistant automating research, scraping, and file operations using LangChain.","desc":"Jarvis is an AI assistant built to automate common research tasks like web scraping, data extraction, and file generation using language models and APIs.","desc1":"I worked on automating workflows using LangChain and Python, integrating web scraping, document generation, and LLM query handling.","desc2":"Through this project, I learned how to orchestrate multiple AI services together for a real-world research and automation application.","statusItem":[{"title":"Category","desc":"AI/LLM Integration"},{"title":"Type","desc":"Personal Research Project"},{"title":"Start Date","desc":"February 2024"},{"title":"Technologies","desc":"Python, LangChain, OpenAI APIs"}],"descItems":[{"title":"Project Goal","desc":"Create an AI-powered virtual assistant for automating knowledge retrieval and file operations."},{"title":"My Role","desc":"Integrated LangChain flows, designed scraping pipelines, and deployed basic task automation APIs."},{"title":"Key Features","desc":"Prompt chaining, document retrieval, automation scripts, and task scheduling."}],"liveLink":"","githubLink":"https://github.com/adithya-crypto/assistant"},{"id":3,"title":"Healthcare ETL Pipeline","category":"Data Engineering","img":"/img/portfolio/etl-thumb.jpg","shortDesc":"Designed and deployed ETL pipelines for ingesting and transforming large datasets into cloud warehouses.","desc":"Built an ETL pipeline for healthcare datasets, automating ingestion, transformation, and loading into a structured database for analytics.","desc1":"Developed Python scripts for cleaning and transforming raw datasets, automated SQL loading scripts, and created basic dashboards for insights.","desc2":"This project helped me gain practical experience in data engineering workflows, automation, and cloud data loading techniques.","statusItem":[{"title":"Category","desc":"Data Engineering"},{"title":"Type","desc":"Academic Project"},{"title":"Start Date","desc":"January 2024"},{"title":"Technologies","desc":"Python, SQL, Pandas, Matplotlib"}],"descItems":[{"title":"Project Goal","desc":"Build a complete ETL workflow for processing healthcare-related datasets and preparing them for reporting."},{"title":"My Role","desc":"Scripted the full pipeline including extraction, cleaning, transformations, and visualizations."},{"title":"Key Features","desc":"ETL automation, SQL schema design, data reporting, and pipeline scheduling basics."}],"liveLink":"https://adithya-crypto-healthcare-data-etl-pipeline-dashboard-p7sgbs.streamlit.app","githubLink":"https://github.com/adithya-crypto/Healthcare-Data-ETL-Pipeline"},{"id":4,"title":"GitHub Scraper","category":"Automation Tool","img":"/img/portfolio/githubscraper-thumb.jpg","shortDesc":"Built a Python scraper to extract GitHub user profiles, repositories, and contribution metrics.","desc":"Developed a Python-based GitHub scraper that uses GitHub APIs and scraping techniques to gather repository data, user statistics, and PR history for analysis.","desc1":"Designed a modular scraper using Python, integrated GitHub\'s REST API, and stored data locally for further reporting and visualization.","desc2":"This project deepened my understanding of APIs, authentication, and data collection best practices.","statusItem":[{"title":"Category","desc":"Web Scraping"},{"title":"Type","desc":"Personal Utility Project"},{"title":"Start Date","desc":"December 2023"},{"title":"Technologies","desc":"Python, GitHub API, Web Scraping"}],"descItems":[{"title":"Project Goal","desc":"Extract and analyze public GitHub data for user profiling and repository analytics."},{"title":"My Role","desc":"Built the scraper, handled API authentication, and designed data storage workflows."},{"title":"Key Features","desc":"Pull request analysis, user profile scraping, data export to CSV/JSON formats."}],"liveLink":"","githubLink":"https://github.com/adithya-crypto/GitHub-scraper"},{"id":5,"title":"Maze Runner","category":"Algorithmic Project","img":"/img/portfolio/mazerunner-thumb.jpg","shortDesc":"Developed and visualized maze-solving algorithms using DFS and BFS techniques in Python.","desc":"Built a visual Python application showcasing how pathfinding algorithms like BFS, DFS, and A* can solve complex mazes efficiently.","desc1":"Implemented search algorithms from scratch and visualized the exploration of nodes and shortest paths dynamically on a GUI.","desc2":"This project enhanced my algorithmic thinking, search pattern understanding, and Python GUI development skills.","statusItem":[{"title":"Category","desc":"Algorithms & Visualization"},{"title":"Type","desc":"Academic Mini Project"},{"title":"Start Date","desc":"November 2023"},{"title":"Technologies","desc":"Python, Tkinter, Algorithm Design"}],"descItems":[{"title":"Project Goal","desc":"Visualize classical search algorithms solving mazes and find optimal paths."},{"title":"My Role","desc":"Designed the visual grid, implemented DFS, BFS, and A* pathfinding logic."},{"title":"Key Features","desc":"Real-time search visualization, adjustable maze difficulty, performance comparison between algorithms."}],"liveLink":"","githubLink":"https://github.com/adithya-crypto/mazerunner"}]'),n=()=>a},5505:(e,t,i)=>{i.d(t,{A:()=>n});let a=JSON.parse('[{"id":1,"authorName":"John A. Cencioso","authorDesig":"Director, NAU Online, Northern Arizona University","desc":"Adithya demonstrates strategic thinking, technical excellence, and an outstanding commitment to professionalism. He maintained a high standard of academic performance while delivering results in dynamic, time-sensitive environments."},{"id":2,"authorName":"Dr. Raman Dugyala","authorDesig":"Professor, Python Programming, Vardhaman College of Engineering","desc":"Adithyaâ€™s logical reasoning, Python expertise, and innovative thinking set him apart academically and professionally. His ability to translate theoretical knowledge into practical solutions was consistently impressive."},{"id":3,"authorName":"Dr. M.A. Jabbar","authorDesig":"Professor, Machine Learning, Vardhaman College of Engineering","desc":"Adithya showcases remarkable leadership, machine learning expertise, and a consistent drive for innovation. He displayed excellent team spirit and remarkable presentation skills during multiple technical events."},{"id":4,"authorName":"Dr. H. Venkateswara Reddy","authorDesig":"Professor, Algorithms, Vardhaman College of Engineering","desc":"Adithya has a strong command of algorithms, project execution, and outstanding collaborative skills. He consistently demonstrated remarkable analytical thinking and enthusiasm for applying new technologies."}]'),n=()=>a}}]);